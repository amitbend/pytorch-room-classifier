\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
%\usepackage[nonatbib]{report}

% to compile a camera-ready version, add the [final] option, e.g.:
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage[final]{report}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{CMP 719 - Computer Vision Assignment 1}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Tayfun Ate≈ü \\
  \texttt{n17230653@cs.hacettepe.edu.tr} \\
}

\begin{document}

\maketitle


\begin{abstract}

This document contains model details and experimental results conducted for the first assigment
of CMP719 course of the Department of Computer Engineering in Hacettepe University.

\end{abstract}

\section{Introduction}

 The deliverables of this homework is provided as a solution of a room classification problem with 15 classes. The classes tried to be learnt are fastfood restaurant, children room, bathroom, closet, tv studio, computer room, clothingstore, gym, auditorium, classroom, bar, garage, dining room, florist, bakery. Report contains three sections which are preparing data, training a classifier from scratch and transfer learning in convolutional neural networks. For the first two sections, a basic deep learning model, whose details are given in section 2, is selected. Experiments conducted on top of this model and the model is updated if experiments result in an accuracy increase on the validation set incrementally. For the last section, instead of using a model created from scratch, we use Resnet18 model \cite{he2016deep} pre-trained with ImageNet dataset  \cite{russakovsky2015imagenet}. By the help of a famous model, we investigate effects of transfer learning. \\
 
 During all experiments and tuning process, only validation test is used to update the best model. After reaching the best model for the validation set, accuracy result is given using test set. Using any data from test set during tuning parameters is considered as cheating and we also avoid doing that.

\section{Part 1 - Preparing Data}

As the dataset, we use MIT's indoor scene recognition dataset \cite{quattoni2009recognizing} which contains 67 indoor scene classes originally. We use only 15 of these classes to train our classifier. These 15 classes contain 2954 images in total. However, only a subset of those images is used for training and testing the model. 80 images for each category are selected for training and 20 images for each category are selected for testing purposes summing 1200 train and 300 test images in total. Train set is also splitted so that 960 of the images are left to train set and 240 images are left to validation set. A random seed of 42 is used for splitting the train set. Splitting process is also stratified so that all classes are equally divided in the train and validation sets.\\

Dataloader for our data is implemented in dataset.py file. Transformations for the dataloaders are stated in config.py. There are basic transformations other than data augmentation which will be further investigated. Some of these basic transtionformations are scaling, resizing and normalizing. All images are converted to scale 0 and  1 and resized to a square size of TODO. While finetuning the model pre-trained on ImageNet, the images are normalized with a mean of 0.485, 0.456, 0.406 and standard deviation of 0.229, 0.224, 0.225 for R, G and B channels in order to make our dataset's distribution similar to that of ImageNet.\\

We use a batch size of 32 which is chosen by considering our resources. For each batch in the train set,  we shuffle our dataset using our dataloader to provide stochasticity. We use a batch size of 1 for test and validation sets and we do not shuffle them.

\section{Part 2 - Training a Classifier from Scratch}

Details about our model go here

\section{Part 3 - Transfer Learning in Convolutional Neural Networks}

Details about finetuning go here 


\section{Conclusions}
 
{\small
\bibliographystyle{ieee}
\bibliography{report}
}


\end{document}
